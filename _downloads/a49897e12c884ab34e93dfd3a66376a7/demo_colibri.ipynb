{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Demo Colibri.\n\nIn this example we show how to use a simple pipeline of end-to-end learning with the CASSI and SPC forward models. Mainly, the forward model is defined,\n\n\\begin{align}\\mathbf{y} = \\mathbf{H}_\\phi \\mathbf{x}\\end{align}\n\nwhere $\\mathbf{H}$ is the forward model, $\\mathbf{x}$ is the input image and $\\mathbf{y}$ is the measurement and $\\phi$ are the coding elements of the forward model. The recovery model is defined as,\n\n\\begin{align}\\mathbf{x} = \\mathcal{G}_\\theta( \\mathbf{y})\\end{align}\n\nwhere $\\mathcal{G}$ is the recovery model and $\\theta$ are the parameters of the recovery model.\n\nThe training is performed by minimizing the following loss function,\n\n\\begin{align}\\{\\phi^*,\\theta^*\\} = \\arg \\min_{\\phi,\\theta} \\sum_{p=1}^{P}\\mathcal{L}(\\mathbf{x}_p, \\mathcal{G}_\\theta( \\mathbf{H}_\\phi \\mathbf{x}_p)) + \\lambda \\mathcal{R}(\\phi) + \\mu \\mathcal{R}(\\mathbf{H}_\\phi \\mathbf{x})\\end{align}\n\nwhere $\\mathcal{L}$ is the loss function, $\\mathcal{R}$ is the regularizer, $\\lambda$ and $\\mu$ are the regularization weights, and $P$ is the number of samples in the training dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Select Working Directory and Device\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os \nos.chdir(os.path.dirname(os.getcwd()))\nprint(\"Current Working Directory \" , os.getcwd())\n\n#General imports\nimport matplotlib.pyplot as plt\nimport torch\nimport os\n\nmanual_device = \"cpu\"\n# Check GPU support\nprint(\"GPU support: \", torch.cuda.is_available())\n\nif manual_device:\n    device = manual_device\nelse:\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from colibri.data.datasets import Dataset\n\ndataset_path = 'cifar10'\nkeys = ''\nbatch_size = 128\ndataset = Dataset(dataset_path, keys, batch_size)\nadquistion_name = 'c_cassi' #  ['spc', 'cassi']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import make_grid\n\nsample = next(iter(dataset.train_dataset))[0]\nimg = make_grid(sample[:32], nrow=8, padding=1, normalize=True, scale_each=False, pad_value=0)\n\nplt.figure(figsize=(10,10))\nplt.imshow(img.permute(1, 2, 0))\nplt.title('CIFAR10 dataset')\nplt.axis('off')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optics forward model\nDefine the forward operators $\\mathbf{y} = \\mathbf{H}_\\phi \\mathbf{x}$, in this case, the CASSI and SPC forward models.  \nEach optics model can comptute the forward and backward operators i.e., $\\mathbf{y} = \\mathbf{H}_\\phi \\mathbf{x}$ and $\\mathbf{x} = \\mathbf{H}^T_\\phi \\mathbf{y}$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import math\nfrom colibri.optics import SPC, SD_CASSI, DD_CASSI, C_CASSI\n\nimg_size = sample.shape[1:]\n\nacquisition_config = dict(\n    input_shape = img_size,\n)\n\nif adquistion_name == 'spc':\n    n_measurements  = 256 \n    n_measurements_sqrt = int(math.sqrt(n_measurements))    \n    acquisition_config['n_measurements'] = n_measurements\n\nacquisition_model = {\n    'spc': SPC(**acquisition_config),\n    'sd_cassi': SD_CASSI(**acquisition_config),\n    'dd_cassi': DD_CASSI(**acquisition_config),\n    'c_cassi': C_CASSI(**acquisition_config)\n}[adquistion_name]\n\ny = acquisition_model(sample)\n\nif adquistion_name == 'spc':\n    y = y.reshape(y.shape[0], -1, n_measurements_sqrt, n_measurements_sqrt)\n\nimg = make_grid(y[:32], nrow=8, padding=1, normalize=True, scale_each=False, pad_value=0)\n\nplt.figure(figsize=(10,10))\nplt.imshow(img.permute(1, 2, 0))\nplt.axis('off')\nplt.title(f'{adquistion_name.upper()} measurements')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reconstruction model\nDefine the recovery model $\\mathbf{x} = \\mathcal{G}_\\theta( \\mathbf{y})$, in this case, a simple U-Net model. \nYou can add you custom model by using the :meth: `build_network` function.\nAdditionally we define the end-to-end model that combines the forward and recovery models.\nDefine the loss function $\\mathcal{L}$, and the regularizers $\\mathcal{R}$ for the forward and recovery models. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from colibri.models import build_network, Unet, Autoencoder\nfrom colibri.misc import E2E\nfrom colibri.train import Training\nfrom colibri.metrics import psnr, ssim\nfrom colibri.regularizers import (\n    Reg_Binary,\n    Reg_Transmittance,\n    MinVariance,\n    KLGaussian,\n)\n\n\nnetwork_config = dict(\n    in_channels=sample.shape[1],\n    out_channels=sample.shape[1],\n    reduce_spatial = True           # Only for Autoencoder\n)\n\nrecovery_model = build_network(Unet, **network_config)\n\nmodel = E2E(acquisition_model, recovery_model)\nmodel = model.to(device)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nlosses = {\"MSE\": torch.nn.MSELoss(), \"L1\": torch.nn.L1Loss()}\nmetrics = {\"PSNR\": psnr, \"SSIM\": ssim}\nlosses_weights = [1.0, 1.0]\n\nn_epochs = 10\nsteps_per_epoch = 10\nfrequency = 1\nregularizers_optics_ce = {\"RB\": Reg_Binary(), \"RT\": Reg_Transmittance()}\nregularizers_optics_ce_weights = [50, 1]\n\nregularizers_optics_mo = {\"MV\": MinVariance(), \"KLG\": KLGaussian(stddev=0.1)}\nregularizers_optics_mo_weights = [1e-3, 0.1]\n\ntrain_schedule = Training(\n    model=model,\n    train_loader=dataset.train_dataset,\n    optimizer=optimizer,\n    loss_func=losses,\n    losses_weights=losses_weights,\n    metrics=metrics,\n    regularizers=None,\n    regularization_weights=None,\n    schedulers=[],\n    callbacks=[],\n    device=device,\n    regularizers_optics_ce=regularizers_optics_ce,\n    regularization_optics_weights_ce=regularizers_optics_ce_weights,\n    regularizers_optics_mo=regularizers_optics_mo,\n    regularization_optics_weights_mo=regularizers_optics_mo_weights,\n)\n\nresults = train_schedule.fit(\n    n_epochs=n_epochs, steps_per_epoch=steps_per_epoch, freq=frequency\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize results\nPerforms the inference $\\tilde{\\mathbf{x}} = \\mathcal{G}_{\\theta^*}( \\mathbf{H}_{\\phi^*}\\mathbf{x})$ and visualize the results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_est = model(sample.to(device)).cpu()\ny = acquisition_model(sample.to(device)).cpu()\n\nif adquistion_name == 'spc':\n    y = y.reshape(y.shape[0], -1, n_measurements_sqrt, n_measurements_sqrt)\n\nimg      = make_grid(sample[:16], nrow=4, padding=1, normalize=True, scale_each=False, pad_value=0)\nimg_est  = make_grid(x_est[:16], nrow=4, padding=1, normalize=True, scale_each=False, pad_value=0)\nimg_y    = make_grid(y[:16], nrow=4, padding=1, normalize=True, scale_each=False, pad_value=0)\n\nimgs_dict = {\n    \"CIFAR10 dataset\": img, \n    f\"{adquistion_name.upper()} measurements\": img_y,\n    \"Recons CIFAR10\": img_est\n}\n\nplt.figure(figsize=(14, 2.7))\n\nfor i, (title, img) in enumerate(imgs_dict.items()):\n    plt.subplot(1, 4, i+1)\n    plt.imshow(img.permute(1, 2, 0))\n    plt.title(title)\n    plt.axis('off')\n\nca = acquisition_model.learnable_optics.cpu().detach().numpy().squeeze()\nif adquistion_name == 'spc':\n    ca = ca = ca.reshape(n_measurements, 32, 32, 1)[0]\nelif adquistion_name == 'c_cassi':\n    ca = ca.transpose(1, 2, 0)\nplt.subplot(1, 4, 4)\nplt.imshow(ca, cmap='gray')\nplt.axis('off')\nplt.title('Learned CA')\nplt.colorbar()\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}