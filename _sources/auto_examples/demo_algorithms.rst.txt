
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/demo_algorithms.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_demo_algorithms.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_demo_algorithms.py:


Demo Algorithms.
===================================================

.. GENERATED FROM PYTHON SOURCE LINES 8-10

Select Working Directory and Device
-----------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 10-35

.. code-block:: Python

    import os 
    os.chdir(os.path.dirname(os.getcwd()))
    print("Current Working Directory " , os.getcwd())

    import sys
    sys.path.append(os.path.join(os.getcwd()))

    #General imports
    import matplotlib.pyplot as plt
    import torch
    import os

    # Set random seed for reproducibility
    torch.manual_seed(0)

    manual_device = "cpu"
    # Check GPU support
    print("GPU support: ", torch.cuda.is_available())

    if manual_device:
        device = manual_device
    else:
        device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Current Working Directory  /home/runner/work/pycolibri/pycolibri
    GPU support:  False




.. GENERATED FROM PYTHON SOURCE LINES 36-38

Load dataset
-----------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 38-49

.. code-block:: Python

    from colibri.data.datasets import Dataset

    dataset_path = 'cifar10'
    keys = ''
    batch_size = 1
    dataset = Dataset(dataset_path, keys, batch_size)
    acquisition_name = 'spc' #  ['spc', 'cassi']








.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Loading dataset:  cifar10
    Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz
      0%|          | 0/170498071 [00:00<?, ?it/s]      2%|▏         | 2785280/170498071 [00:00<00:06, 27687138.09it/s]      7%|▋         | 12746752/170498071 [00:00<00:02, 69867240.78it/s]     13%|█▎        | 22740992/170498071 [00:00<00:01, 83162693.86it/s]     19%|█▊        | 31621120/170498071 [00:00<00:01, 85328218.52it/s]     25%|██▍       | 41779200/170498071 [00:00<00:01, 91006476.55it/s]     30%|██▉       | 50888704/170498071 [00:00<00:01, 86869603.30it/s]     35%|███▌      | 60325888/170498071 [00:00<00:01, 89217578.13it/s]     41%|████      | 69304320/170498071 [00:00<00:01, 84621746.13it/s]     47%|████▋     | 80379904/170498071 [00:00<00:00, 92328933.78it/s]     53%|█████▎    | 89817088/170498071 [00:01<00:00, 92814893.59it/s]     59%|█████▉    | 101220352/170498071 [00:01<00:00, 99093165.35it/s]     65%|██████▌   | 111247360/170498071 [00:01<00:00, 99370437.44it/s]     71%|███████   | 121241600/170498071 [00:01<00:00, 99007385.03it/s]     77%|███████▋  | 132055040/170498071 [00:01<00:00, 101703828.31it/s]     83%|████████▎ | 142278656/170498071 [00:01<00:00, 99210369.08it/s]      90%|████████▉ | 153157632/170498071 [00:01<00:00, 101993185.15it/s]     96%|█████████▌| 163414016/170498071 [00:01<00:00, 100452881.07it/s]    100%|██████████| 170498071/170498071 [00:01<00:00, 93917540.29it/s] 
    Extracting ./data/cifar-10-python.tar.gz to ./data
    Files already downloaded and verified




.. GENERATED FROM PYTHON SOURCE LINES 50-52

Visualize dataset
-----------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 52-58

.. code-block:: Python

    from torchvision.utils import make_grid
    from colibri.recovery.transforms import DCT2D

    sample = next(iter(dataset.train_dataset))[0]









.. GENERATED FROM PYTHON SOURCE LINES 59-70

.. code-block:: Python



    transform_dct = DCT2D()

    theta = transform_dct.forward(sample)
    x_hat = transform_dct.inverse(theta)

    error = torch.norm(sample - x_hat)
    print("Error: ", error  )






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Error:  tensor(4.1239e-06)




.. GENERATED FROM PYTHON SOURCE LINES 71-72

Optics forward model

.. GENERATED FROM PYTHON SOURCE LINES 72-153

.. code-block:: Python


    import math
    from colibri.optics import SPC, SD_CASSI, DD_CASSI, C_CASSI

    img_size = sample.shape[1:]

    acquisition_config = dict(
        input_shape = img_size,
    )

    if acquisition_name == 'spc':
        n_measurements  = 25**2 
        n_measurements_sqrt = int(math.sqrt(n_measurements))    
        acquisition_config['n_measurements'] = n_measurements

    acquisition_model = {
        'spc': SPC(**acquisition_config),
        'sd_cassi': SD_CASSI(**acquisition_config),
        'dd_cassi': DD_CASSI(**acquisition_config),
        'c_cassi': C_CASSI(**acquisition_config)
    }[acquisition_name]

    y = acquisition_model(sample)

    # Reconstruct image
    from colibri.recovery.fista import Fista
    from colibri.recovery.terms.prior import Sparsity
    from colibri.recovery.terms.fidelity import L2
    from colibri.recovery.transforms import DCT2D

    algo_params = {
        'max_iter': 200,
        'alpha': 1e-4,
        'lambda': 0.001,
        'tol': 1e-3
    }



    fidelity = L2()
    prior = Sparsity()
    transform = DCT2D()

    fista = Fista(fidelity, prior, acquisition_model, algo_params, transform)

    x0 = acquisition_model.forward(y, type_calculation="backward")
    x_hat = fista(y, x0=x0 ) 

    print(x_hat.shape)

    plt.figure(figsize=(10,10))

    plt.subplot(1,4,1)
    plt.title('Reference')
    plt.imshow(sample[0,:,:].permute(1, 2, 0), cmap='gray')
    plt.xticks([])
    plt.yticks([])

    plt.subplot(1,4,2)
    plt.title('Sparse Representation')
    plt.imshow(abs(theta[0,:,:]).permute(1, 2, 0), cmap='gray')
    plt.xticks([])
    plt.yticks([])


    if acquisition_name == 'spc':
        y = y.reshape(y.shape[0], -1, n_measurements_sqrt, n_measurements_sqrt)


    plt.subplot(1,4,3)
    plt.title('Measurement')
    plt.imshow(y[0,:,:].permute(1, 2, 0), cmap='gray')
    plt.xticks([])
    plt.yticks([])

    plt.subplot(1,4,4)
    plt.title('Reconstruction')
    x_hat -= x_hat.min()
    x_hat /= x_hat.max()
    plt.imshow(x_hat[0,:,:].permute(1, 2, 0).detach().cpu().numpy(), cmap='gray')
    plt.xticks([])
    plt.yticks([])


.. image-sg:: /auto_examples/images/sphx_glr_demo_algorithms_001.png
   :alt: Reference, Sparse Representation, Measurement, Reconstruction
   :srcset: /auto_examples/images/sphx_glr_demo_algorithms_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    torch.Size([1, 3, 32, 32])
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [8.956995e-07..19.173409].
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-63.544357..55.10225].

    ([], [])




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 7.183 seconds)


.. _sphx_glr_download_auto_examples_demo_algorithms.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: demo_algorithms.ipynb <demo_algorithms.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: demo_algorithms.py <demo_algorithms.py>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
